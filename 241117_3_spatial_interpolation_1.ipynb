{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adrien Gahéry**\n",
    "<img align=\"right\" src=\"https://pysal.org/tobler/_images/tobler_long.png\" alt=\"Tobler logo\" height=250>\n",
    "\n",
    "In this notebook, we are using [Tobler](https://pysal.org/tobler/) to wrangle PostGIS Data ! The goal is to interpolate population statistics into a hex grid. \n",
    "\n",
    "# Building the data\n",
    "\n",
    "We're fecthing France INSEE's population data. The INSEE is a public administration. It has been gerrymandering the territory into spatial division representing roughly the same amount of people. These are called [ilôts IRIS](https://www.insee.fr/fr/statistiques/4799309#consulter). INSEE also produces a square grid of equidistant scale layed over France's territory. \n",
    "We'll also blend in the [calculated area of city attraction](https://www.insee.fr/fr/information/4803954), which is also a dataset from the INSEE.\n",
    " \n",
    "We'll later pitch this data againt the [ZNIEFF datasets](https://www.data.gouv.fr/fr/datasets/inpn-donnees-du-programme-znieff/) We'll use it on Tobler as a catagorical variable.\n",
    "\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "# import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine, text, bindparam\n",
    "# import psycopg2\n",
    "from tobler.area_weighted import area_interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection\n",
    "db_url = \"postgresql+psycopg2://Adrien:postgres@localhost:5432/montpellier\" # \"dialect+driver://username:password@host:port/database\"\n",
    "engine = create_engine(db_url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Fist, We've got to link the csv file to its [contours](https://www.data.gouv.fr/fr/datasets/contours-iris-1/). We'll import that data into our database. We'll pick the [2017 edition](https://data.geopf.fr/telechargement/download/CONTOURS-IRIS/CONTOURS-IRIS_2-1__SHP__FRA_2018-06-08/CONTOURS-IRIS_2-1__SHP__FRA_2018-06-08.7z), matching the year of the corresponding data.\n",
    "Hint: Turn the CSV file into a DBF file (export as Shp in QGIS), then use the DataBase manager to import the file in PostGIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = text(\"\"\"\n",
    "            SELECT ROW_NUMBER() OVER() as id, geometry as geom\n",
    "            FROM w.hex_clip_5000\n",
    "            \"\"\")\n",
    "hex_clip = gpd.read_postgis(stmt, engine)\n",
    "\n",
    "stmt = text(\"\"\"\n",
    "            SELECT ROW_NUMBER() OVER() as id, a.iris, a.com, a.typ_iris, a.lab_iris, b.id AS b_id,  b.insee_com, b.nom_com, b.nom_iris,\n",
    "                a.p17_pop, a.p17_pop000, a.p17_pop030, a.p17_pop061, a.p17_pop111, a.p17_pop182, a.p17_pop253, a.p17_pop405, a.p17_pop556, a.p17_pop657, a.p17_pop80p, a.p17_pop001, a.p17_pop152, a.p17_pop304,\n",
    "                a.p17_pop455, a.p17_pop607, a.p17_pop75p, a.p17_pop0_1, a.p17_pop206, a.p17_pop65p, a.p17_poph, a.p17_h0014, a.p17_h1529, a.p17_h3044, a.p17_h4559, a.p17_h6074, a.p17_h75p, a.p17_h0019,\n",
    "                a.p17_h2064, a.p17_h65p, a.p17_popf, a.p17_f0014, a.p17_f1529, a.p17_f3044, a.p17_f4559, a.p17_f6074, a.p17_f75p, a.p17_f0019, a.p17_f2064, a.p17_f65p, a.c17_pop15p, a.c17_pop1_1,\n",
    "                a.c17_pop1_2, a.c17_pop1_3, a.c17_pop1_4, a.c17_pop1_5, a.c17_pop1_6, a.c17_pop1_7, a.c17_pop1_8, a.c17_h15p, a.c17_h15p_c, a.c17_h15p_1, a.c17_h15p_2, a.c17_h15p_3, a.c17_h15p_4,\n",
    "                a.c17_h15p_5, a.c17_h15p_6, a.c17_h15p_7, a.c17_f15p, a.c17_f15p_c, a.c17_f15p_1, a.c17_f15p_2, a.c17_f15p_3, a.c17_f15p_4, a.c17_f15p_5, a.c17_f15p_6, a.c17_f15p_7,\n",
    "                a.p17_pop_fr, a.p17_pop_et, a.p17_pop_im, a.p17_pmen, a.p17_phorme,\n",
    "                b.geom\n",
    "            FROM pop_2017 AS a, iris_s AS b\n",
    "            WHERE a.iris = b.code_iris\n",
    "            \"\"\")\n",
    "iris = gpd.read_postgis(stmt, engine)\n",
    "# iris.head(2)\n",
    "# iris.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_clip.plot();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've been quickly checking the data's Coordinate Reference System. EPSG 2154 is the legal SRID for mainland France. Our data is \"healthy\".\n",
    "\n",
    "We've been importing the whole dataset, turns out the overall population estimate is ```p17_pop```. The rest of the data is the same data, slice per gender and age range. One might as well come up with an age pyramid for each poloygon out of this data.\n",
    "\n",
    "There might also be an interrsting data in the city drag in France. This requires a bit more thinking through on how I'm laying my interpolations, since there is no perfect geometric match between the two files, even though they're built from the same elements, i.e. IRIS polygons, dating different years.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = text(\"\"\"\n",
    "            SELECT id, geom, aav2020, libaav2020, taav2017, nb_com \n",
    "            FROM aav2020_2024\n",
    "            \"\"\")\n",
    "citydrag = gpd.read_postgis(stmt, engine)\n",
    "# citydrag.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grooming City drag classes\n",
    "citydrag_classes = {\"Aire de Paris\"                                 :'from_paris_area',\n",
    "                    \"Aire de 700 000 habitants ou plus (hors Paris)\":'from_700k_pax_or_more',\n",
    "                    \"Aire de 200 000 à moins de 700 000 habitants\"  :'from_200k_to_700h_pax',\n",
    "                    \"Aire de 50 000 à moins de 200 000 habitants\"   :'from_50k_to_200k_pax',\n",
    "                    \"Aire de moins de 50 000 habitants\"             :'from_less_than_50k_pax'}\n",
    "\n",
    "citydrag['citydrag_area']=citydrag['taav2017'].map(citydrag_classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add in some data that is not meant to geometrically line up with our IRIS polygons. The [ZNIEFF datasets](https://www.data.gouv.fr/fr/datasets/inpn-donnees-du-programme-znieff/) are the official area of faunistic and floristic interest in France. There are two types, and their area may overlap, hence two different layers, even if their atributes share the same fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = text(\"\"\"\n",
    "            SELECT id, nom, id_mnhn, id_org, generation, geom FROM znieff1_s\n",
    "            \"\"\")\n",
    "znieff1 = gpd.read_postgis(stmt, engine)\n",
    "\n",
    "stmt = text(\"\"\"\n",
    "            SELECT id, nom, id_mnhn, id_org, generation, geom FROM znieff2_s\n",
    "            \"\"\")\n",
    "znieff2 = gpd.read_postgis(stmt, engine)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Overlap Ratios\n",
    "\n",
    "I set a \"dummy column\" that I'm calling 'ratio'. It is intended to figure out the geometry overlap of intensive values over the target dataframe, hence tracking the source of the interpolated value. I'll pass it as a categorical variable in the [area_interpolate()](https://pysal.org/tobler/generated/tobler.area_weighted.area_interpolate.html) method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "znieff1['znieff1_overlap'] = znieff1['id'].apply(lambda s: 'ratio')\n",
    "znieff2['znieff2_overlap'] = znieff2['id'].apply(lambda s: 'ratio')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_iris= area_interpolate(source_df=iris, target_df=hex_clip, \n",
    "                              intensive_variables=['p17_pop', 'p17_pop000', 'p17_pop030', 'p17_pop061', 'p17_pop111', 'p17_pop182', 'p17_pop253', 'p17_pop405', 'p17_pop556', 'p17_pop657', 'p17_pop80p', 'p17_pop001', 'p17_pop152', 'p17_pop304',\n",
    "                                                  'p17_pop455', 'p17_pop607', 'p17_pop75p', 'p17_pop0_1', 'p17_pop206', 'p17_pop65p', 'p17_poph', 'p17_h0014', 'p17_h1529', 'p17_h3044', 'p17_h4559', 'p17_h6074', 'p17_h75p', 'p17_h0019',\n",
    "                                                  'p17_h2064', 'p17_h65p', 'p17_popf', 'p17_f0014', 'p17_f1529', 'p17_f3044', 'p17_f4559', 'p17_f6074', 'p17_f75p', 'p17_f0019', 'p17_f2064', 'p17_f65p', 'c17_pop15p', 'c17_pop1_1',\n",
    "                                                  'c17_pop1_2', 'c17_pop1_3', 'c17_pop1_4', 'c17_pop1_5', 'c17_pop1_6', 'c17_pop1_7', 'c17_pop1_8', 'c17_h15p', 'c17_h15p_c', 'c17_h15p_1', 'c17_h15p_2', 'c17_h15p_3', 'c17_h15p_4',\n",
    "                                                  'c17_h15p_5', 'c17_h15p_6', 'c17_h15p_7', 'c17_f15p', 'c17_f15p_c', 'c17_f15p_1', 'c17_f15p_2', 'c17_f15p_3', 'c17_f15p_4', 'c17_f15p_5', 'c17_f15p_6', 'c17_f15p_7',\n",
    "                                                  'p17_pop_fr', 'p17_pop_et', 'p17_pop_im', 'p17_pmen', 'p17_phorme'],\n",
    "                              categorical_variables=['typ_iris'],\n",
    "                              spatial_index = 'target'           # seems to improve overall performance.\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_drag = area_interpolate(source_df=citydrag, target_df=hex_clip,\n",
    "                                categorical_variables=['citydrag_area'],\n",
    "                                spatial_index = 'target')\n",
    "hex_drag.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_nieff1 = area_interpolate(source_df=znieff1, target_df=hex_clip, spatial_index = 'target',\n",
    "                                categorical_variables=['znieff1_overlap'],)\n",
    "hex_nieff2 = area_interpolate(source_df=znieff2, target_df=hex_clip, spatial_index = 'target',\n",
    "                                categorical_variables=['znieff2_overlap'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PostGIS\n",
    "\n",
    "We'll import these calculated GeoDataFrames to PostGIS to merge them into a single table. Pandas.[merge](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.merge.html) does merge by indexes, but its resuls is not a GeoDataFrame anymore, even though it retains both geometries. Since this is data management, I'll go with postGIS\n",
    "\n",
    "\n",
    "Area Interpolate does not supply us with an id field, so we'll do a spatial join. I'm comparing centroids per centroid, since the geometry is shared by all layers.\n",
    "\n",
    "### Importing the results to PostGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_iris.to_postgis(\"hex_iris\", schema=\"w\", con=engine, if_exists='replace')\n",
    "hex_drag.to_postgis(\"hex_drag\", schema=\"w\", con=engine, if_exists='replace')\n",
    "hex_nieff1.to_postgis(\"hex_nieff1\", schema=\"w\", con=engine, if_exists='replace')\n",
    "hex_nieff2.to_postgis(\"hex_nieff2\", schema=\"w\", con=engine, if_exists='replace')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial request\n",
    "\n",
    "We'll go ahead and merge the tables with spatial SQL. We are not loading the data straight out of the request, we'll control our work in QGIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.begin() as connection:\n",
    "    stmt=text(\"\"\"\n",
    "              DROP TABLE IF EXISTS w.hex_termediate;\n",
    "               \"\"\")\n",
    "    connection.execute(stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.begin() as connection:\n",
    "    stmt=text(\"\"\"\n",
    "              DROP TABLE IF EXISTS w.hex_sql_5000;\n",
    "              WITH znieffs as (SELECT a.znieff1_overlap_ratio, b.znieff2_overlap_ratio, b.geometry as geom\n",
    "                    FROM w.hex_nieff1 as a, w.hex_nieff2 as b\n",
    "                    WHERE ST_intersects(ST_centroid(a.geometry), ST_centroid(b.geometry))),\n",
    "                  zdrag as (SELECT a.znieff1_overlap_ratio, a.znieff2_overlap_ratio, \n",
    "                    b.citydrag_area_from_less_than_50k_pax, b.citydrag_area_from_700k_pax_or_more, b.citydrag_area_from_200k_to_700h_pax, b.citydrag_area_from_50k_to_200k_pax, b.citydrag_area_from_paris_area,\n",
    "                    b.geometry as geom\n",
    "                    FROM znieffs as a, w.hex_drag as b\n",
    "                    WHERE ST_intersects(ST_centroid(a.geom), ST_centroid(b.geometry)))\n",
    "              SELECT b.znieff1_overlap_ratio, b.znieff2_overlap_ratio, b.citydrag_area_from_less_than_50k_pax, b.citydrag_area_from_700k_pax_or_more, b.citydrag_area_from_200k_to_700h_pax, b.citydrag_area_from_50k_to_200k_pax, b.citydrag_area_from_paris_area,\n",
    "                    a.p17_pop, a.p17_pop000, a.p17_pop030, a.p17_pop061, a.p17_pop111, a.p17_pop182, a.p17_pop253, a.p17_pop405, a.p17_pop556, a.p17_pop657, a.p17_pop80p, a.p17_pop001, a.p17_pop152, a.p17_pop304, a.p17_pop455, a.p17_pop607, a.p17_pop75p, a.p17_pop0_1, a.p17_pop206, a.p17_pop65p, a.p17_poph, a.p17_h0014, a.p17_h1529, a.p17_h3044, a.p17_h4559, a.p17_h6074, a.p17_h75p, a.p17_h0019, a.p17_h2064, a.p17_h65p, a.p17_popf, a.p17_f0014, a.p17_f1529, a.p17_f3044, a.p17_f4559, a.p17_f6074, a.p17_f75p, a.p17_f0019, a.p17_f2064, a.p17_f65p,\n",
    "                    a.c17_pop15p, a.c17_pop1_1, a.c17_pop1_2, a.c17_pop1_3, a.c17_pop1_4, a.c17_pop1_5, a.c17_pop1_6, a.c17_pop1_7, a.c17_pop1_8, a.c17_h15p, a.c17_h15p_c, a.c17_h15p_1, a.c17_h15p_2, a.c17_h15p_3, a.c17_h15p_4, a.c17_h15p_5, a.c17_h15p_6, a.c17_h15p_7, a.c17_f15p, a.c17_f15p_c, a.c17_f15p_1, a.c17_f15p_2, a.c17_f15p_3, a.c17_f15p_4, a.c17_f15p_5, a.c17_f15p_6, a.c17_f15p_7,\n",
    "                    a.p17_pop_fr, a.p17_pop_et, a.p17_pop_im, a.p17_pmen, a.p17_phorme, a.\"typ_iris_Z\" AS typ_iris_z, a.\"typ_iris_H\" AS typ_iris_h, a.\"typ_iris_D\" AS typ_iris_d, a.\"typ_iris_A\" AS typ_iris_a, a.geometry as geom\n",
    "                  INTO w.hex_sql_5000\n",
    "                  FROM zdrag as b, w.hex_iris as a\n",
    "                  WHERE ST_intersects(ST_centroid(a.geometry), ST_centroid(b.geom));\n",
    "              DROP TABLE IF EXISTS w.hex_iris;\n",
    "              DROP TABLE IF EXISTS w.hex_drag;\n",
    "              DROP TABLE IF EXISTS w.hex_nieff1;\n",
    "              DROP TABLE IF EXISTS w.hex_nieff2;\n",
    "              \"\"\")\n",
    "    connection.execute(stmt)\n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Let's enjoy our work ! \n",
    "\n",
    "### The GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt=text(\"\"\"\n",
    "      SELECT * FROM w.hex_sql_5000\n",
    "        \"\"\")\n",
    "\n",
    "hex_sql_5000 = gpd.read_postgis(stmt, engine)\n",
    "hex_sql_5000.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextily as ctx\n",
    "\n",
    "transparency = 0.75\n",
    "transparency_ctx = 0.6\n",
    "ctx_source = ctx.providers.GeoportailFrance.plan\n",
    "\n",
    "stmt = text(\"\"\"\n",
    "            SELECT\n",
    "            znieff1_overlap_ratio, znieff2_overlap_ratio, \n",
    "            citydrag_area_from_less_than_50k_pax, citydrag_area_from_700k_pax_or_more, citydrag_area_from_200k_to_700h_pax, citydrag_area_from_50k_to_200k_pax, citydrag_area_from_paris_area, \n",
    "            p17_pop, p17_pop000, p17_pop030, p17_pop061, p17_pop111, p17_pop182, p17_pop253, p17_pop405, p17_pop556, p17_pop657, p17_pop80p, p17_pop001, p17_pop152, p17_pop304, p17_pop455, p17_pop607, p17_pop75p,\n",
    "            p17_pop0_1, p17_pop206, p17_pop65p, p17_poph, p17_h0014, p17_h1529, p17_h3044, p17_h4559, p17_h6074, p17_h75p, p17_h0019, p17_h2064, p17_h65p, p17_popf, p17_f0014, p17_f1529, p17_f3044, p17_f4559, p17_f6074, p17_f75p,\n",
    "            p17_f0019, p17_f2064, p17_f65p, c17_pop15p, c17_pop1_1, c17_pop1_2, c17_pop1_3, c17_pop1_4, c17_pop1_5, c17_pop1_6, c17_pop1_7, c17_pop1_8, c17_h15p, c17_h15p_c, c17_h15p_1, c17_h15p_2, c17_h15p_3, c17_h15p_4, c17_h15p_5, c17_h15p_6, c17_h15p_7, c17_f15p, c17_f15p_c, c17_f15p_1, c17_f15p_2, c17_f15p_3, c17_f15p_4, c17_f15p_5, c17_f15p_6, c17_f15p_7, p17_pop_fr, p17_pop_et, p17_pop_im, p17_pmen, p17_phorme,\n",
    "            typ_iris_z, typ_iris_h, typ_iris_d, typ_iris_a,\n",
    "            ST_Transform(geom, :crs) as geom\n",
    "            FROM w.hex_sql_5000\n",
    "            \"\"\").bindparams(crs = 3857)  # spherical mercator for Contextily\n",
    "hex_sql = gpd.read_postgis(stmt, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10,7), facecolor=(.16,.16,.16))\n",
    "fig.suptitle('Interpolation of opulation data to hexagonal cells in France\\'s Hérault')\n",
    "\n",
    "basemap = fig.add_subplot()\n",
    "\n",
    "hex_sql.plot(ax=basemap, column='p17_pop', alpha=transparency, legend=True, \n",
    "                           \n",
    "             legend_kwds={\"label\": \"Population per hex cell\", \"orientation\": \"horizontal\",\"shrink\":0.8,},\n",
    "             cmap='viridis', zorder=2)\n",
    "ctx.add_basemap(ax=basemap,source=ctx_source, alpha=transparency_ctx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n",
    "- [ilôts IRIS](https://www.insee.fr/fr/statistiques/4799309#consulter) : data only\n",
    "- [contours IRIS](https://www.data.gouv.fr/fr/datasets/contours-iris-1/) : Geography only\n",
    "- [ZNIEFF datasets](https://www.data.gouv.fr/fr/datasets/inpn-donnees-du-programme-znieff/) : proper GIS file\n",
    "- [BD_Topo®](https://geoservices.ign.fr/bdtopo) data from France's IGN®, which is copied on a localhost database for convenience. We could use [\"Département 34 - Hérault\"](https://geoservices.ign.fr/bdtopo#telechargementshpdept) in particular.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Virutual_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
